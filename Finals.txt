AWS regions and Load Balancing

Regions:
Regions are Isolated from each other
in regions there are multiple/ no of  availability zones

availability zones:
1) When you launch an instance, you can select an Availability 
    Zone or let AWS choose one for you. If you distribute your instances
    across multiple Availability Zones and one instance fails, you can design 
    your application so that an instance in another Availability Zone can handle requests.

2) You can also use Elastic IP addresses to mask the failure of an instance in one Availability 
    Zone by rapidly remapping the address to an instance in another Availability Zone.

3) An Availability Zone is represented by a region codefollowed by a letter identifier; for example, us-east-1a. To ensure that resources are distributed across the Availability Zones for a region, AWS independently map Availability Zones to identifiers for each account. For example, your Availability Zone us-east-1a might not be the same location as us-east-1a for another account. There's no way for you to coordinate Availability Zones between accounts.
   

LoadBalancer:

1)  A load balancer is a device that acts as a reverse proxy and distributes network or application traffic across a number of servers
2) Load balancers are used to increase capacity (concurrent users) and reliability of applications.
3) Load balancers ensure reliability and availability by monitoring the "health" of applications and only sending requests to servers and applications that can respond in a timely manner
4) They improve the overall performance of applications by decreasing the burden on servers associated with managing and maintaining application and network sessions, as well as by performing application-specific tasks.

Types: 

Layer 4 Load Balancers:
Layer 4 load balancers act upon data found in network and transport layer protocols (IP, TCP, FTP, UDP). 

Layer 7 Load Balancers-
Layer 7 load balancers distribute requests based upon data found in application layer protocols such as HTTP.CSYE 6225, Fall 2018, Tejas Parikh, Northeastern University12

requests distributon algorithms

1) round orbin
2) weighted round robin
3) least connections
4) least response time

Layer 7 load balancers can further distribute requests based on application specific data such as HTTP headers, cookies, or data within the application message itself, such as the value of a specific parameter.CSYE 6225, Fall 2018, Tejas Parikh, Northeastern University13


--->> Classic Load balancer:

The Classic Load Balancer routes traffic based on application or network level information and is ideal for simple load balancing of traffic across multiple EC2 instances where high availability, automatic scaling, and robust security are required.CSYE 6225, Fall 2018, Tejas Parikh, Northeastern University15

--->> features?

High Availability 
•Health Checks
•SSL offloading   -------->?
•Sticky Sessions
•Layer 4 or 7 Load Balancing
•Access Logs
•Operational Monitoring


---->>Application Load Balancer

An Application Load Balancer is a load balancing option for the Elastic Load Balancing service that operates at the application layer and allows you to define routing rules based on content across multiple services or containers running on one or more Amazon Elastic Compute Cloud (Amazon EC2) instances.

features:

•Host-based routing
•Path-based routing
•HTTP/2 Support
•WebSocketsSupport
•Health Checks
•Layer 7 Load Balancing
•SSL Offloading
•Request Tracking
•Web Application Firewall
•Containerized Application Support



Load balancer features:

1) Assymetric load
2) DDOs tack protection 
3) HTtP compression  ----------> ??

---->> network lod balanacer

1)  Network Load Balancer operates at the connection level (Layer 4), routing connections to targets -Amazon EC2 instances, containers and IP addresses based on IP protocol data.
2)  Ideal for load balancing of TCP traffic, Network Load Balancer is capable of handling millions of requests per second while maintaining ultra-low latencies. 
3)  Network Load Balancer is optimized to handle sudden and volatile traffic patterns while using a single static IP address per Availability Zone.
4)  It is integrated with other popular AWS services such as Auto Scaling, Amazon EC2 Container Service (ECS), and Amazon CloudFormation


features

•Connection-based Load Balancing:
You can load balance TCP traffic, routing connections to targets -Amazon EC2 instances, microservices and containers, and IP addresses.

•Preserve source IP address:
Network Load Balancer preserves the client side source IP allowing the back-end to see the IP address of the client.

•Static IP support:

Network Load Balancer automatically provides a static IP per Availability Zone (subnet) that can be used by applications as the front-end IP of the load balancer.
•Long-lived TCP Connections:
Network Load Balancer supports long-lived TCP connections that are ideal for WebSockettype of applications.

•Central API Support:
Network Load Balancer uses the same API as Application Load Balancer. This will enable you to work with target groups, health checks, and load balance across multiple ports on the same Amazon EC2 instance to support containerized applications



AutoScaling:

Autoscaling is a method used in cloud computing, whereby the amount of computational resources in a server farm, typically measured in terms of the number of active servers, scales automatically based on the load on the farm. •It is closely related to, and builds upon, the idea of load balancing

Auto Scaling detects impaired compute instances and unhealthy applications, and replace the instances without human intervention ensuring that your application is getting the compute capacity it needs

1. Monitor the health of running instances
2. Replace impaired instances automatically
3. Balance capacity across Availability Zones

Dynamic scaling:



Scaling policies:

Manual scaling:     specify max and min values and ec2 autoscaling manages after things
Scheduled scaling : when you know exactly when you will need to increase or decrease
dynamic scaling   : scale by policy,when you want to scale in respond to changing conditions,

how it is different from manual scaling?


Scale out:

scale out ---- > to create the ec2  instances

scale in ----> to delete the ec2 instances

The cooldown period is a configurable setting for your Auto Scaling group that helps to ensure that it doesn't launch or terminate additional instances before the previous scaling activity takes effect. •After the Auto Scaling group dynamically scales using a simple scaling policy, it waits for the cooldown period to complete before resuming scaling activities.•Cooldown periods are notsupported for scheduled scaling.CSYE 6225, Fall 2018, Tejas Parikh, Northeastern University36


Content Delivery Network (CDN)

1) A content delivery network or content distribution network (CDN) is a geographically distributed network of proxy servers and their data centers.
2) A CDN allows for the quick transfer of assets needed for loading Internet content including HTML pages, JavaScript files, stylesheets, images, and videos
3) The popularity of CDN services continues to grow, and today the majority of web traffic is served through CDNs, including traffic from major sites like Facebook, Netflix, and Amazon.

Benefits:

a) Improving website load times
b) Reducing bandwidth costs
c) Increasing content availability and redundancy
d) Improving website security :  security by providing ddos mitigation


origin Server:

The purpose of an origin server is to process and respond to incoming Internet requests from Internet clients.

origin vs caching vs edge server


A CDN edge server:

at logical extreme or edge of a N/W.
an edge server often seves as the connection between seperate networks

--- > A primary purpose of a CDN edge server is to store content as close as possible to a requesting client machine, 
      thereby reducing latency and improving page load times?


host computer----- > edge -------------> origin server
             <<------      <<-----------

What is anycast:

: Anycast is a network addressing and routing method in which incoming requests can be routed to a variety of different locations or “nodes.”

1) typically routes incoming traffic to the nearest data center with the capacity to process the request efficiently. 

2) Selective routing allows an Anycast network to be resilient in the face of high traffic volume, network congestion, and DDoS attacks.

working of CDN: 

a) At its core, a CDN is a network of servers linked together with the goal of delivering content as quickly, cheaply, reliably, and securely as possible.

b) In order to improve speed and connectivity, a CDN will place servers at the exchange points between different networks.

c) These Internet exchange points (IXPs) are the primary locations where different Internet providers connect in order to provide each other access to traffic originating on their different networks. 

e) By having a connection to these high speed and highly interconnected locations, a CDN provider is able to reduce costs and transit times in high speed data delivery.


AWS cloud Front edge N/W:

cache

types of HTTP requests supported by cloud front

GET•HEAD•POST•PUT•PATCH•DELETE •OPTIONS

Note: Amazon CloudFront does not cache the responses to POST, PUT, DELETE, and PATCH requests –these requests are proxied back to the origin server


How does a CDN improve website load times?

{
// to do nd write
}

{

}


-------- >> <<---------- >> << -------- >> << ---------
CLOUD and Application security

1) Confidentiality: only authorised party can get access.

2) INtegerity: guarantees that the data send matches that the data receieved

3) authenticity: data coming from an authorised source

4) Availability : Service should be accessible and usable during a specified time period.

5) Threat: In computer security a threat is a possible danger that might exploit a vulnerability to breach security and therefore cause possible harm.

6) vulnerability:  vulnerability is a weakness that can be exploited


Attack Vectors:

a) An attack vector is a path or means by which a hacker can gain access to a computer or network server in order to deliver a payload or malicious outcome.

b) Attack vectors enable hackers to exploit system vulnerabilities, including the human element.


Risk: Risk is the possibility of loss or harm arising from performing an activity

Security ControlsSecurity:  controls are countermeasures used to prevent or respond to security threats and to reduce or avoid risk

Threat Agent :A threat agent is an entity that poses a threat because it is capable of carrying out an attack


CLOUD SECURITY THREATS:

1) Traffic eaves dropping : when data is being transferred to or within a cloud service is passively itercepted
                            compromise the confidentiality of the data, bcz of the passive nature attack go undeteceted?

2) Malicious Intermediary : when msgs are intercepted andlatered by a malicious service agent, compromising the messege confidentiality
                            may also insert harmful data

3) Insufficient Authorization: when access is granted to an attacker erroneously, resulting in the exposure to
                            IT resources that are normally protected.

4) Denial of Service: purpose of this attack is to overlaod the resources to the point where they cannot function properly. Can be launched in 
                    the following way

5) Flawed Implementation: substandard design, Implementation or configuration of service and its deployment can have undesirable consequences.
                          inherent flaws can have vulnerabilities, and have potential risks


Cloud Security Mechanism

ENcryption: converting plaint text data into a protected and unreadable format so that it can be transferred over a network
            encryption can help cpunter the traffic eavesdropping, malicious Intermediary,insuffeceiant Authorization
            these are of two types:

            a) Symmetric b) Asymmetric

Symmetric Encryption: symmetric encryption uses the same key for both encryption and decryption
                       both performed by auth parties having one shared key.

                        It is also known as secret key cryptography, same key for encryp and decryption

                        parties who crypt and decrypt show evidence of performance
                        of the act

                        basic auth is performed as to check party with can only create messeges

Assymetric Encryption : relies on use of 2 diff keys, namesly private and public
                        it is also refered to as public key cryptography,
                       a) Private key: only owner has it,
                       b) Public key : commonly available

                       a document that was encrpted with aprivate key can only be correctly
                       decrypted with the corresponding public key?

                       conversly , document that was encrypted with the public key can be decrypted only by its private counter parties

                       thats why 2 diff keys, it is always computaionally slower then the symmetric encryption


Securing Web Based Data transission:

secure web based data transmission is applied via https
https--- > uses SSL/TLS (transport layer securoty) a successor of ssl.

            assym more time, TLS uses asym for key exchange then TLS change to key exchange method

            TLS supprt RSA-- as chief assymetric encryption cipher

            Triple DES and AED are supported for symmetric encryption

SSL handshake:

Hashing: The hashing mechanism is used when a one-way, non-reversible form of data protection is required

        Hashing can be used to derive a message digest from a message, which is often of a fixed length and smaller than the original message.

        The message sender can then utilize the hashing mechanism to attach the message digest to the message. •The recipient applies the same
         hash function to the message to verify that the produced message digest is identical to the one that accompanied the message.
         •Any alteration to the original data results in an entirely different message digest and clearly indicates that tampering has occurred

Digital signature:
A message is assigned a digital signature prior to transmission, which is then rendered invalid if the message experiences any subsequent, unauthorized modifications.
Both hashing and asymmetrical encryption are involved in the creation of a digital signature, which essentially exists as a message digest that was encrypted by a private key and appended to the original message.
The recipient verifies the signature validity and uses the corresponding public key to decrypt the digital signature, which produces the message digest. •The hashing mechanism can also be applied to the original message to produce this message digest. Identical results from the two different processes indicate that the message maintained its integrity.


Hardening is the process of stripping unnecessary software from a system to limit potential vulnerabilities that can be exploited by attackers.


Handling the hackers:
MApping the application

bypassing client side controls



cross-site scripting

XSS enables attackers to inject client-side scripts into web pages viewed by other users. 
•A cross-site scripting vulnerability may be used by attackers to bypass access controls such as the same-origin policy


Cross-site request forgery:

not a theft of datat changing state of request


COntainers:

Ease of Deployment 

isolation
efefceinvy
better packing

containers are nothing but a process on linux

isolation and resource confinement is what makes a Linux process a Linux container

cgroups limits how much you can use
•Namespaces limits what you can see (and therefore use)

Multiple namespaces: pid, net, mnt, uts, ipc, user

The docker container engine manages the configuration of Linux kernel namespaces, additional security features, and cgroups


Docker is a simple client/server model

Docker called registry which stores Docker images and metadata about those images.

Docker Client –The docker command used to control most of the Docker workflow and to talk to remote Docker servers.

Docker Server –The docker command run in the daemon mode

Docker image-- > Rootfs and JSON

the layering : create a new JSON file, and tar the difference between the original image and the new image with the updated JSON file. This creates a layered imag

The definition of a container image was eventually standardized by the Open Container Initiative (OCI) 

limitation of containers: they use kernel of host linux machine, if they require a specific version of kernel then
                           there  might be a chance that the it wont run on any linux host, where as VMs do not have this restriction

Container Registry
•Docker took these container images (tarballs) and moved them to a web service from which they could be pulled, developed a protocol to pull them, 
and called the web service a container registry.

Container engines
Container engines are programs that can pull container images from container registries and reassemble them onto container storage.•Container engines also launch container runtimes.

Container Storage
•Container storage is usually a copy-on-write (COW) layered filesystem. When you pull down a container image from a container registry, you first need to untarthe rootfsand place it on disk.
•If you have multiple layers that make up your image, each layer is downloaded and stored on a different layer on the COW filesystem.
•The COW filesystem allows each layer to be stored separately, which maximizes sharing for layered images

Container Runtime Configuration
•After the container engine downloads the container image to container storage, it needs to create a container runtime configuration.
•The runtime configuration combines input from the caller/user along with the content of the container image specification.
•For example, the caller might want to specify modifications to a running container's security, add additional environment variables, or mount volumes to the container.•The layout of the container runtime configuration and the exploded rootfshave also been standardized by the OCI standards body as the OCI Runtime Specification







----------->> <<------------------->> <<--------------->> <<----------------->> <<-----------------------

 Recite:
   
    regions vs availability zones:
    failures
    elastic IP
    load balancer and layers

    types of scaling policies and also scaling

these are events

which siz of group it is refering to 

 ?? Anycast ??





----------->> <<------------------->> <<--------------->> <<----------------->> <<-----------------------
QUESTIONS

----->>>elastic load balanacer vs classic load balancer?

static ip per availability zone vs Elastic IP

 need to read about DDos attacks

diff between auto scaling and load balancing

how it(dynamic) is different from manual scaling?

Scale out---->> how they are related to cpu usage scaling

what is the meaning increasing the size of the groups

cooldowns are like a buffer period before it starts scaling>

need to know what exactly what cdn is

cdns are nothing but caching servers?

origin vs caching vs edge sercer?

what are cookies?

dsicuss some netwrking basic terms as well for tomorrow

how  traffic eavesdropping is a passive attack?

it says passively intercepted data for illegal information gathering,

Then it can also get the information from the messfe as well making it similar to malicious Intermediary


Symmetric vs assymetric keys, in asymetric key working needed to be discussed to understand that

access control??



